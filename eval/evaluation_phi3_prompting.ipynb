{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gundruke/micromamba/envs/thesis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torcheval.metrics import MultilabelAccuracy\n",
    "import torch\n",
    "from prettytable import PrettyTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"results/phi3_prompting/prompt1.csv\")\n",
    "df2 = pd.read_csv(\"results/phi3_prompting/prompt2.csv\")\n",
    "df3 = pd.read_csv(\"results/phi3_prompting/prompt3.csv\")\n",
    "df4 = pd.read_csv(\"results/phi3_prompting/prompt4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1[[\"text\", \"category\", \"polarity\", \"joint\", \"category_labels\", \"polarity_labels\", \"joint_labels\", \"true_labels\", \"prompt_1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prompt_2\"] = df2[\"prompt_2\"]\n",
    "df[\"prompt_3\"] = df3[\"prompt_3\"]\n",
    "df[\"prompt_4\"] = df4[\"prompt_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>joint</th>\n",
       "      <th>category_labels</th>\n",
       "      <th>polarity_labels</th>\n",
       "      <th>joint_labels</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>prompt_1</th>\n",
       "      <th>prompt_2</th>\n",
       "      <th>prompt_3</th>\n",
       "      <th>prompt_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bread top notch well</td>\n",
       "      <td>['food']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['food#positive']</td>\n",
       "      <td>[0 1 0 0 0]</td>\n",
       "      <td>[0 0 1]</td>\n",
       "      <td>[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]</td>\n",
       "      <td>{'ambience': None, 'food': 'positive', 'other'...</td>\n",
       "      <td>{'quality':'high','food':'positive'}</td>\n",
       "      <td>{'quality':'high','food':'positive'}</td>\n",
       "      <td>{'quality':'high','food':'positive'}</td>\n",
       "      <td>{'quality':'high','food':'positive'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>say one fastest delivery times city</td>\n",
       "      <td>['service']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['service#positive']</td>\n",
       "      <td>[0 0 0 0 1]</td>\n",
       "      <td>[0 0 1]</td>\n",
       "      <td>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]</td>\n",
       "      <td>{'ambience': None, 'food': None, 'other': None...</td>\n",
       "      <td>The fastest delivery times in the city typica...</td>\n",
       "      <td>The fastest delivery times in the city typica...</td>\n",
       "      <td>The fastest delivery times in the city typica...</td>\n",
       "      <td>The fastest delivery times in the city typica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text     category      polarity  \\\n",
       "0                 bread top notch well     ['food']  ['positive']   \n",
       "1  say one fastest delivery times city  ['service']  ['positive']   \n",
       "\n",
       "                  joint category_labels polarity_labels  \\\n",
       "0     ['food#positive']     [0 1 0 0 0]         [0 0 1]   \n",
       "1  ['service#positive']     [0 0 0 0 1]         [0 0 1]   \n",
       "\n",
       "                      joint_labels  \\\n",
       "0  [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]   \n",
       "1  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]   \n",
       "\n",
       "                                         true_labels  \\\n",
       "0  {'ambience': None, 'food': 'positive', 'other'...   \n",
       "1  {'ambience': None, 'food': None, 'other': None...   \n",
       "\n",
       "                                            prompt_1  \\\n",
       "0               {'quality':'high','food':'positive'}   \n",
       "1   The fastest delivery times in the city typica...   \n",
       "\n",
       "                                            prompt_2  \\\n",
       "0               {'quality':'high','food':'positive'}   \n",
       "1   The fastest delivery times in the city typica...   \n",
       "\n",
       "                                            prompt_3  \\\n",
       "0               {'quality':'high','food':'positive'}   \n",
       "1   The fastest delivery times in the city typica...   \n",
       "\n",
       "                                            prompt_4  \n",
       "0               {'quality':'high','food':'positive'}  \n",
       "1   The fastest delivery times in the city typica...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category_labels\"] = df[\"category_labels\"].apply(lambda x: [int(y) for y in x.strip(\"[\").strip(\"]\").split(\" \")])\n",
    "df[\"polarity_labels\"] = df[\"polarity_labels\"].apply(lambda x: [int(y) for y in x.strip(\"[\").strip(\"]\").split(\" \")])\n",
    "df[\"joint_labels\"]    =    df[\"joint_labels\"].apply(lambda x: [int(y) for y in x.strip(\"[\").strip(\"]\").split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = {\n",
    "    \"true_labels\": [],\n",
    "    \"prompt_1\": [],\n",
    "    \"prompt_2\": [],\n",
    "    \"prompt_3\":  [],\n",
    "    \"prompt_4\": []\n",
    "    }\n",
    "for i, x in df.iterrows():\n",
    "    filtered[\"true_labels\"].append({k:v for k,v in eval(x[\"true_labels\"]).items() if v is not None})\n",
    "\n",
    "    for shot in ['prompt_1', 'prompt_2', 'prompt_3', 'prompt_4']: \n",
    "        try:\n",
    "            _dict = eval(x[shot])\n",
    "            if not isinstance(_dict, dict):\n",
    "                _dict = {}\n",
    "        except:\n",
    "            _dict = {}\n",
    "\n",
    "        filtered[shot].append(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in filtered.items():\n",
    "    df[k] = filtered[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed keys and values\n",
    "allowed_keys = [\"food\", \"service\", \"ambience\", \"price\", \"other\"]\n",
    "allowed_values = [\"positive\", \"neutral\", \"negative\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_singular_cols(df, col):\n",
    "    aspects =  []\n",
    "    sentiments = []\n",
    "\n",
    "    # Iterate through the DataFrame and process each row\n",
    "    for index, row in df.iterrows():\n",
    "        label_dict = row[col]\n",
    "    \n",
    "        # Filter keys and values\n",
    "        filtered_keys = list(set([key for key in label_dict.keys() if key in allowed_keys]))\n",
    "        filtered_values = list(set([value for value in label_dict.values() if value in allowed_values]))\n",
    "\n",
    "        filtered_keys.sort()\n",
    "        filtered_values.sort()\n",
    "    \n",
    "        aspects.append(filtered_keys)\n",
    "        sentiments.append(filtered_values)\n",
    "    \n",
    "    return aspects, sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shot in ['prompt_1', 'prompt_2', 'prompt_3', 'prompt_4']:\n",
    "    aspects, sentiments = get_singular_cols(df, shot)\n",
    "    \n",
    "    df[f\"aspect_{shot}\"] = aspects\n",
    "    df[f\"sentiment_{shot}\"] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>joint</th>\n",
       "      <th>category_labels</th>\n",
       "      <th>polarity_labels</th>\n",
       "      <th>joint_labels</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>prompt_1</th>\n",
       "      <th>prompt_2</th>\n",
       "      <th>prompt_3</th>\n",
       "      <th>prompt_4</th>\n",
       "      <th>aspect_prompt_1</th>\n",
       "      <th>sentiment_prompt_1</th>\n",
       "      <th>aspect_prompt_2</th>\n",
       "      <th>sentiment_prompt_2</th>\n",
       "      <th>aspect_prompt_3</th>\n",
       "      <th>sentiment_prompt_3</th>\n",
       "      <th>aspect_prompt_4</th>\n",
       "      <th>sentiment_prompt_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bread top notch well</td>\n",
       "      <td>['food']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['food#positive']</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>{'food': 'positive'}</td>\n",
       "      <td>{'quality': 'high', 'food': 'positive'}</td>\n",
       "      <td>{'quality': 'high', 'food': 'positive'}</td>\n",
       "      <td>{'quality': 'high', 'food': 'positive'}</td>\n",
       "      <td>{'quality': 'high', 'food': 'positive'}</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>say one fastest delivery times city</td>\n",
       "      <td>['service']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['service#positive']</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>{'service': 'positive'}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text     category      polarity  \\\n",
       "0                 bread top notch well     ['food']  ['positive']   \n",
       "1  say one fastest delivery times city  ['service']  ['positive']   \n",
       "\n",
       "                  joint  category_labels polarity_labels  \\\n",
       "0     ['food#positive']  [0, 1, 0, 0, 0]       [0, 0, 1]   \n",
       "1  ['service#positive']  [0, 0, 0, 0, 1]       [0, 0, 1]   \n",
       "\n",
       "                                    joint_labels              true_labels  \\\n",
       "0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]     {'food': 'positive'}   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  {'service': 'positive'}   \n",
       "\n",
       "                                  prompt_1  \\\n",
       "0  {'quality': 'high', 'food': 'positive'}   \n",
       "1                                       {}   \n",
       "\n",
       "                                  prompt_2  \\\n",
       "0  {'quality': 'high', 'food': 'positive'}   \n",
       "1                                       {}   \n",
       "\n",
       "                                  prompt_3  \\\n",
       "0  {'quality': 'high', 'food': 'positive'}   \n",
       "1                                       {}   \n",
       "\n",
       "                                  prompt_4 aspect_prompt_1 sentiment_prompt_1  \\\n",
       "0  {'quality': 'high', 'food': 'positive'}          [food]         [positive]   \n",
       "1                                       {}              []                 []   \n",
       "\n",
       "  aspect_prompt_2 sentiment_prompt_2 aspect_prompt_3 sentiment_prompt_3  \\\n",
       "0          [food]         [positive]          [food]         [positive]   \n",
       "1              []                 []              []                 []   \n",
       "\n",
       "  aspect_prompt_4 sentiment_prompt_4  \n",
       "0          [food]         [positive]  \n",
       "1              []                 []  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi label binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_1\n",
      "{0: 'negative', 1: 'neutral', 2: 'positive'}\n",
      "{0: 'ambience', 1: 'food', 2: 'other', 3: 'price', 4: 'service'}\n",
      "\n",
      "prompt_2\n",
      "{0: 'negative', 1: 'neutral', 2: 'positive'}\n",
      "{0: 'ambience', 1: 'food', 2: 'other', 3: 'price', 4: 'service'}\n",
      "\n",
      "prompt_3\n",
      "{0: 'negative', 1: 'neutral', 2: 'positive'}\n",
      "{0: 'ambience', 1: 'food', 2: 'other', 3: 'price', 4: 'service'}\n",
      "\n",
      "prompt_4\n",
      "{0: 'negative', 1: 'neutral', 2: 'positive'}\n",
      "{0: 'ambience', 1: 'food', 2: 'other', 3: 'price', 4: 'service'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_mlb = MultiLabelBinarizer()\n",
    "sentiment_mlb = MultiLabelBinarizer()\n",
    "\n",
    "category_mlb.fit([[\"food\", \"service\", \"ambience\", \"price\", \"other\"]])\n",
    "sentiment_mlb.fit([[\"positive\", \"neutral\", \"negative\"]])\n",
    "\n",
    "for shot in ['prompt_1', 'prompt_2', 'prompt_3', 'prompt_4']:\n",
    "    df[f\"aspect_{shot}_label\"] = category_mlb.transform(df[f\"aspect_{shot}\"]).tolist()\n",
    "    df[f\"sentiment_{shot}_label\"] = sentiment_mlb.transform(df[f\"sentiment_{shot}\"]).tolist()\n",
    "\n",
    "    aspect_idx_to_text = dict(zip(range(len(category_mlb.classes_)), category_mlb.classes_))\n",
    "    category_idx_to_text = dict(zip(range(len(sentiment_mlb.classes_)), sentiment_mlb.classes_))\n",
    "    print(shot)\n",
    "    print(category_idx_to_text)\n",
    "    print(aspect_idx_to_text)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>joint</th>\n",
       "      <th>category_labels</th>\n",
       "      <th>polarity_labels</th>\n",
       "      <th>joint_labels</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>prompt_1</th>\n",
       "      <th>prompt_2</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect_prompt_4</th>\n",
       "      <th>sentiment_prompt_4</th>\n",
       "      <th>aspect_prompt_1_label</th>\n",
       "      <th>sentiment_prompt_1_label</th>\n",
       "      <th>aspect_prompt_2_label</th>\n",
       "      <th>sentiment_prompt_2_label</th>\n",
       "      <th>aspect_prompt_3_label</th>\n",
       "      <th>sentiment_prompt_3_label</th>\n",
       "      <th>aspect_prompt_4_label</th>\n",
       "      <th>sentiment_prompt_4_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bread top notch well</td>\n",
       "      <td>['food']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['food#positive']</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>{'food': 'positive'}</td>\n",
       "      <td>{'quality': 'high', 'food': 'positive'}</td>\n",
       "      <td>{'quality': 'high', 'food': 'positive'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>say one fastest delivery times city</td>\n",
       "      <td>['service']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['service#positive']</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>{'service': 'positive'}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food always fresh ready eat</td>\n",
       "      <td>['food']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['food#positive']</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>{'food': 'positive'}</td>\n",
       "      <td>{'food': 'positive', 'ready_to_eat': 'positive'}</td>\n",
       "      <td>{'food': 'positive', 'ready_to_eat': 'positive'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mention coffee outstanding</td>\n",
       "      <td>['food']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['food#positive']</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>{'food': 'positive'}</td>\n",
       "      <td>{'coffee': 'positive'}</td>\n",
       "      <td>{'coffee': 'positive'}</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trust people go sushi never disappoints</td>\n",
       "      <td>['other']</td>\n",
       "      <td>['positive']</td>\n",
       "      <td>['other#positive']</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>{'other': 'positive'}</td>\n",
       "      <td>{'trust': 'positive', 'sushi': 'positive', 'ne...</td>\n",
       "      <td>{'trust': 'positive', 'sushi': 'positive', 'ne...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text     category      polarity  \\\n",
       "0                     bread top notch well     ['food']  ['positive']   \n",
       "1      say one fastest delivery times city  ['service']  ['positive']   \n",
       "2              food always fresh ready eat     ['food']  ['positive']   \n",
       "3               mention coffee outstanding     ['food']  ['positive']   \n",
       "4  trust people go sushi never disappoints    ['other']  ['positive']   \n",
       "\n",
       "                  joint  category_labels polarity_labels  \\\n",
       "0     ['food#positive']  [0, 1, 0, 0, 0]       [0, 0, 1]   \n",
       "1  ['service#positive']  [0, 0, 0, 0, 1]       [0, 0, 1]   \n",
       "2     ['food#positive']  [0, 1, 0, 0, 0]       [0, 0, 1]   \n",
       "3     ['food#positive']  [0, 1, 0, 0, 0]       [0, 0, 1]   \n",
       "4    ['other#positive']  [0, 0, 1, 0, 0]       [0, 0, 1]   \n",
       "\n",
       "                                    joint_labels              true_labels  \\\n",
       "0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]     {'food': 'positive'}   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]  {'service': 'positive'}   \n",
       "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]     {'food': 'positive'}   \n",
       "3  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]     {'food': 'positive'}   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]    {'other': 'positive'}   \n",
       "\n",
       "                                            prompt_1  \\\n",
       "0            {'quality': 'high', 'food': 'positive'}   \n",
       "1                                                 {}   \n",
       "2   {'food': 'positive', 'ready_to_eat': 'positive'}   \n",
       "3                             {'coffee': 'positive'}   \n",
       "4  {'trust': 'positive', 'sushi': 'positive', 'ne...   \n",
       "\n",
       "                                            prompt_2  ... aspect_prompt_4  \\\n",
       "0            {'quality': 'high', 'food': 'positive'}  ...          [food]   \n",
       "1                                                 {}  ...              []   \n",
       "2   {'food': 'positive', 'ready_to_eat': 'positive'}  ...          [food]   \n",
       "3                             {'coffee': 'positive'}  ...              []   \n",
       "4  {'trust': 'positive', 'sushi': 'positive', 'ne...  ...              []   \n",
       "\n",
       "  sentiment_prompt_4 aspect_prompt_1_label sentiment_prompt_1_label  \\\n",
       "0         [positive]       [0, 1, 0, 0, 0]                [0, 0, 1]   \n",
       "1                 []       [0, 0, 0, 0, 0]                [0, 0, 0]   \n",
       "2         [positive]       [0, 1, 0, 0, 0]                [0, 0, 1]   \n",
       "3         [positive]       [0, 0, 0, 0, 0]                [0, 0, 1]   \n",
       "4         [positive]       [0, 0, 0, 0, 0]                [0, 0, 1]   \n",
       "\n",
       "  aspect_prompt_2_label sentiment_prompt_2_label aspect_prompt_3_label  \\\n",
       "0       [0, 1, 0, 0, 0]                [0, 0, 1]       [0, 1, 0, 0, 0]   \n",
       "1       [0, 0, 0, 0, 0]                [0, 0, 0]       [0, 0, 0, 0, 0]   \n",
       "2       [0, 1, 0, 0, 0]                [0, 0, 1]       [0, 1, 0, 0, 0]   \n",
       "3       [0, 0, 0, 0, 0]                [0, 0, 1]       [0, 0, 0, 0, 0]   \n",
       "4       [0, 0, 0, 0, 0]                [0, 0, 1]       [0, 0, 0, 0, 0]   \n",
       "\n",
       "  sentiment_prompt_3_label aspect_prompt_4_label sentiment_prompt_4_label  \n",
       "0                [0, 0, 1]       [0, 1, 0, 0, 0]                [0, 0, 1]  \n",
       "1                [0, 0, 0]       [0, 0, 0, 0, 0]                [0, 0, 0]  \n",
       "2                [0, 0, 1]       [0, 1, 0, 0, 0]                [0, 0, 1]  \n",
       "3                [0, 0, 1]       [0, 0, 0, 0, 0]                [0, 0, 1]  \n",
       "4                [0, 0, 1]       [0, 0, 0, 0, 0]                [0, 0, 1]  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(test_labels, predictions):\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "    exact_accuracy = MultilabelAccuracy(criteria='exact_match')\n",
    "    exact_accuracy.update(target=torch.Tensor(test_labels), input=torch.Tensor(predictions))\n",
    "\n",
    "    overlap_accuracy = MultilabelAccuracy(criteria='overlap')\n",
    "    overlap_accuracy.update(target=torch.Tensor(test_labels), input=torch.Tensor(predictions))\n",
    "\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "\n",
    "    metrics = {}\n",
    "    metrics = {\n",
    "        'accuracy' : accuracy,\n",
    "        'exact_match_accuracy': exact_accuracy.compute().detach().item(),\n",
    "        'overlap_accuracy': overlap_accuracy.compute().detach().item(),\n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_f1': micro_f1\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def pretty_table(dict):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['metric', 'value']\n",
    "    for k,v in dict.items():\n",
    "        table.add_row([k, v])\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'category', 'polarity', 'joint', 'category_labels',\n",
       "       'polarity_labels', 'joint_labels', 'true_labels', 'prompt_1',\n",
       "       'prompt_2', 'prompt_3', 'prompt_4', 'aspect_prompt_1',\n",
       "       'sentiment_prompt_1', 'aspect_prompt_2', 'sentiment_prompt_2',\n",
       "       'aspect_prompt_3', 'sentiment_prompt_3', 'aspect_prompt_4',\n",
       "       'sentiment_prompt_4', 'aspect_prompt_1_label',\n",
       "       'sentiment_prompt_1_label', 'aspect_prompt_2_label',\n",
       "       'sentiment_prompt_2_label', 'aspect_prompt_3_label',\n",
       "       'sentiment_prompt_3_label', 'aspect_prompt_4_label',\n",
       "       'sentiment_prompt_4_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_prompt_1_label category_labels\n",
      "+----------------------+---------------------+\n",
      "|        metric        |        value        |\n",
      "+----------------------+---------------------+\n",
      "|       accuracy       | 0.13351134846461948 |\n",
      "| exact_match_accuracy | 0.13351134955883026 |\n",
      "|   overlap_accuracy   |  0.3044058680534363 |\n",
      "|       macro_f1       | 0.32543116354991175 |\n",
      "|       micro_f1       | 0.42097902097902096 |\n",
      "+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "true = \"category_labels\"\n",
    "pred = \"aspect_prompt_1_label\"\n",
    "print(pred, true)\n",
    "pretty_table(model_metrics(np.array(df[pred].tolist()), np.array(df[true].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_prompt_2_label category_labels\n",
      "+----------------------+---------------------+\n",
      "|        metric        |        value        |\n",
      "+----------------------+---------------------+\n",
      "|       accuracy       | 0.13351134846461948 |\n",
      "| exact_match_accuracy | 0.13351134955883026 |\n",
      "|   overlap_accuracy   |  0.3044058680534363 |\n",
      "|       macro_f1       | 0.32543116354991175 |\n",
      "|       micro_f1       | 0.42097902097902096 |\n",
      "+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "true = \"category_labels\"\n",
    "pred = \"aspect_prompt_2_label\"\n",
    "print(pred, true)\n",
    "pretty_table(model_metrics(np.array(df[pred].tolist()), np.array(df[true].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_prompt_3_label category_labels\n",
      "+----------------------+---------------------+\n",
      "|        metric        |        value        |\n",
      "+----------------------+---------------------+\n",
      "|       accuracy       | 0.13351134846461948 |\n",
      "| exact_match_accuracy | 0.13351134955883026 |\n",
      "|   overlap_accuracy   |  0.3044058680534363 |\n",
      "|       macro_f1       | 0.32543116354991175 |\n",
      "|       micro_f1       | 0.42097902097902096 |\n",
      "+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "true = \"category_labels\"\n",
    "pred = \"aspect_prompt_3_label\"\n",
    "print(pred, true)\n",
    "pretty_table(model_metrics(np.array(df[pred].tolist()), np.array(df[true].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect_prompt_4_label category_labels\n",
      "+----------------------+---------------------+\n",
      "|        metric        |        value        |\n",
      "+----------------------+---------------------+\n",
      "|       accuracy       | 0.13351134846461948 |\n",
      "| exact_match_accuracy | 0.13351134955883026 |\n",
      "|   overlap_accuracy   |  0.3044058680534363 |\n",
      "|       macro_f1       | 0.32543116354991175 |\n",
      "|       micro_f1       | 0.42097902097902096 |\n",
      "+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "true = \"category_labels\"\n",
    "pred = \"aspect_prompt_4_label\"\n",
    "print(pred, true)\n",
    "pretty_table(model_metrics(np.array(df[pred].tolist()), np.array(df[true].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_prompt_1_label polarity_labels\n",
      "+----------------------+---------------------+\n",
      "|        metric        |        value        |\n",
      "+----------------------+---------------------+\n",
      "|       accuracy       | 0.40587449933244324 |\n",
      "| exact_match_accuracy | 0.40587449073791504 |\n",
      "|   overlap_accuracy   |  0.5180240273475647 |\n",
      "|       macro_f1       |  0.4588083545899923 |\n",
      "|       micro_f1       |  0.6064318529862175 |\n",
      "+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "true = \"polarity_labels\"\n",
    "pred = \"sentiment_prompt_1_label\"\n",
    "print(pred, true)\n",
    "pretty_table(model_metrics(np.array(df[pred].tolist()), np.array(df[true].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_prompt_2_label polarity_labels\n",
      "+----------------------+---------------------+\n",
      "|        metric        |        value        |\n",
      "+----------------------+---------------------+\n",
      "|       accuracy       | 0.40587449933244324 |\n",
      "| exact_match_accuracy | 0.40587449073791504 |\n",
      "|   overlap_accuracy   |  0.5180240273475647 |\n",
      "|       macro_f1       |  0.4588083545899923 |\n",
      "|       micro_f1       |  0.6064318529862175 |\n",
      "+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "true = \"polarity_labels\"\n",
    "pred = \"sentiment_prompt_2_label\"\n",
    "print(pred, true)\n",
    "pretty_table(model_metrics(np.array(df[pred].tolist()), np.array(df[true].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_prompt_3_label polarity_labels\n",
      "+----------------------+---------------------+\n",
      "|        metric        |        value        |\n",
      "+----------------------+---------------------+\n",
      "|       accuracy       | 0.40587449933244324 |\n",
      "| exact_match_accuracy | 0.40587449073791504 |\n",
      "|   overlap_accuracy   |  0.5180240273475647 |\n",
      "|       macro_f1       |  0.4588083545899923 |\n",
      "|       micro_f1       |  0.6064318529862175 |\n",
      "+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "true = \"polarity_labels\"\n",
    "pred = \"sentiment_prompt_3_label\"\n",
    "print(pred, true)\n",
    "pretty_table(model_metrics(np.array(df[pred].tolist()), np.array(df[true].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_prompt_4_label polarity_labels\n",
      "+----------------------+---------------------+\n",
      "|        metric        |        value        |\n",
      "+----------------------+---------------------+\n",
      "|       accuracy       | 0.40587449933244324 |\n",
      "| exact_match_accuracy | 0.40587449073791504 |\n",
      "|   overlap_accuracy   |  0.5180240273475647 |\n",
      "|       macro_f1       |  0.4588083545899923 |\n",
      "|       micro_f1       |  0.6064318529862175 |\n",
      "+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "true = \"polarity_labels\"\n",
    "pred = \"sentiment_prompt_4_label\"\n",
    "print(pred, true)\n",
    "pretty_table(model_metrics(np.array(df[pred].tolist()), np.array(df[true].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_exact_match_accuracy(df, pred_col_name):\n",
    "    exact_matches = df.apply(lambda row: row['true_labels'] == row[pred_col_name], axis=1)\n",
    "    exact_match_accuracy = exact_matches.mean()\n",
    "    return exact_match_accuracy\n",
    "\n",
    "def calculate_partial_accuracy(df, pred_col_name):\n",
    "    def partial_match(row):\n",
    "        true_keys = set(row['true_labels'].keys())\n",
    "        pred_keys = set(row[pred_col_name].keys())\n",
    "        matching_keys = true_keys & pred_keys\n",
    "        if len(true_keys) == 0:\n",
    "            return 0\n",
    "        return len(matching_keys) / len(true_keys)\n",
    "    \n",
    "    partial_accuracies = df.apply(partial_match, axis=1)\n",
    "    partial_accuracy = partial_accuracies.mean()\n",
    "    return partial_accuracy\n",
    "\n",
    "def count_extra_keys(df, pred_col_name):\n",
    "    def extra_key_count(row):\n",
    "        true_keys = set(row['true_labels'].keys())\n",
    "        pred_keys = set(row[pred_col_name].keys())\n",
    "        extra_keys = pred_keys - true_keys\n",
    "        return len(extra_keys)\n",
    "    \n",
    "    extra_keys_counts = df.apply(extra_key_count, axis=1)\n",
    "    return extra_keys_counts.sum()\n",
    "\n",
    "def count_rows_with_extra_keys(df, pred_col_name):\n",
    "    def has_extra_keys(row):\n",
    "        true_keys = set(row['true_labels'].keys())\n",
    "        pred_keys = set(row[pred_col_name].keys())\n",
    "        extra_keys = pred_keys - true_keys\n",
    "        return len(extra_keys) > 0\n",
    "    \n",
    "    rows_with_extra_keys = df.apply(has_extra_keys, axis=1)\n",
    "    return rows_with_extra_keys.sum()\n",
    "\n",
    "def count_empty_predicted_labels(df, pred_col):\n",
    "    empty_predicted_labels = df[pred_col].apply(lambda x: len(x) == 0)\n",
    "    return empty_predicted_labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_1\n",
      "Exact Match Accuracy: 0.03471295060080107\n",
      "Partial Accuracy: 0.26045838896306184\n",
      "Count of Extra Keys: 1284\n",
      "Number of Rows with Extra Keys: 510\n",
      "Number of Rows with Empty Predicted Labels: 207\n",
      "Total: 749\n"
     ]
    }
   ],
   "source": [
    "pred_col = \"prompt_1\"\n",
    "print(pred_col)\n",
    "\n",
    "exact_match_accuracy = calculate_exact_match_accuracy(df, pred_col)\n",
    "partial_accuracy = calculate_partial_accuracy(df, pred_col)\n",
    "extra_key_count = count_extra_keys(df, pred_col)\n",
    "rows_with_extra_keys = count_rows_with_extra_keys(df, pred_col)\n",
    "empty_predicted_labels_count = count_empty_predicted_labels(df, pred_col)\n",
    "\n",
    "\n",
    "print(f'Exact Match Accuracy: {exact_match_accuracy}')\n",
    "print(f'Partial Accuracy: {partial_accuracy}')\n",
    "print(f'Count of Extra Keys: {extra_key_count}')\n",
    "print(f'Number of Rows with Extra Keys: {rows_with_extra_keys}')\n",
    "print(f'Number of Rows with Empty Predicted Labels: {empty_predicted_labels_count}')\n",
    "print(f'Total: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_2\n",
      "Exact Match Accuracy: 0.03471295060080107\n",
      "Partial Accuracy: 0.26045838896306184\n",
      "Count of Extra Keys: 1284\n",
      "Number of Rows with Extra Keys: 510\n",
      "Number of Rows with Empty Predicted Labels: 207\n",
      "Total: 749\n"
     ]
    }
   ],
   "source": [
    "pred_col = \"prompt_2\"\n",
    "print(pred_col)\n",
    "\n",
    "exact_match_accuracy = calculate_exact_match_accuracy(df, pred_col)\n",
    "partial_accuracy = calculate_partial_accuracy(df, pred_col)\n",
    "extra_key_count = count_extra_keys(df, pred_col)\n",
    "rows_with_extra_keys = count_rows_with_extra_keys(df, pred_col)\n",
    "empty_predicted_labels_count = count_empty_predicted_labels(df, pred_col)\n",
    "\n",
    "print(f'Exact Match Accuracy: {exact_match_accuracy}')\n",
    "print(f'Partial Accuracy: {partial_accuracy}')\n",
    "print(f'Count of Extra Keys: {extra_key_count}')\n",
    "print(f'Number of Rows with Extra Keys: {rows_with_extra_keys}')\n",
    "print(f'Number of Rows with Empty Predicted Labels: {empty_predicted_labels_count}')\n",
    "print(f'Total: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_3\n",
      "Exact Match Accuracy: 0.03471295060080107\n",
      "Partial Accuracy: 0.26045838896306184\n",
      "Count of Extra Keys: 1284\n",
      "Number of Rows with Extra Keys: 510\n",
      "Number of Rows with Empty Predicted Labels: 207\n",
      "Total: 749\n"
     ]
    }
   ],
   "source": [
    "pred_col = \"prompt_3\"\n",
    "print(pred_col)\n",
    "\n",
    "exact_match_accuracy = calculate_exact_match_accuracy(df, pred_col)\n",
    "partial_accuracy = calculate_partial_accuracy(df, pred_col)\n",
    "extra_key_count = count_extra_keys(df, pred_col)\n",
    "rows_with_extra_keys = count_rows_with_extra_keys(df, pred_col)\n",
    "empty_predicted_labels_count = count_empty_predicted_labels(df, pred_col)\n",
    "\n",
    "print(f'Exact Match Accuracy: {exact_match_accuracy}')\n",
    "print(f'Partial Accuracy: {partial_accuracy}')\n",
    "print(f'Count of Extra Keys: {extra_key_count}')\n",
    "print(f'Number of Rows with Extra Keys: {rows_with_extra_keys}')\n",
    "print(f'Number of Rows with Empty Predicted Labels: {empty_predicted_labels_count}')\n",
    "print(f'Total: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_4\n",
      "Exact Match Accuracy: 0.03471295060080107\n",
      "Partial Accuracy: 0.26045838896306184\n",
      "Count of Extra Keys: 1284\n",
      "Number of Rows with Extra Keys: 510\n",
      "Number of Rows with Empty Predicted Labels: 207\n",
      "Total: 749\n"
     ]
    }
   ],
   "source": [
    "pred_col = \"prompt_4\"\n",
    "print(pred_col)\n",
    "\n",
    "exact_match_accuracy = calculate_exact_match_accuracy(df, pred_col)\n",
    "partial_accuracy = calculate_partial_accuracy(df, pred_col)\n",
    "extra_key_count = count_extra_keys(df, pred_col)\n",
    "rows_with_extra_keys = count_rows_with_extra_keys(df, pred_col)\n",
    "empty_predicted_labels_count = count_empty_predicted_labels(df, pred_col)\n",
    "\n",
    "print(f'Exact Match Accuracy: {exact_match_accuracy}')\n",
    "print(f'Partial Accuracy: {partial_accuracy}')\n",
    "print(f'Count of Extra Keys: {extra_key_count}')\n",
    "print(f'Number of Rows with Extra Keys: {rows_with_extra_keys}')\n",
    "print(f'Number of Rows with Empty Predicted Labels: {empty_predicted_labels_count}')\n",
    "print(f'Total: {df.shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
